{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Classify CK+ moderate images into ModEm folder\n",
    "import os\n",
    "\n",
    "for root, dirs, files in os.walk(\"./cohn-kanade-images2\"):\n",
    "    filelist=[]\n",
    "    for name in files:\n",
    "        filename = os.path.join(root, name)\n",
    "        if '.png' in filename:\n",
    "            filelist.append(filename)\n",
    "    if len(filelist) > 0:\n",
    "        modfile = filelist[int(len(filelist)/2)]\n",
    "        !cp $modfile ModEm\n",
    "        print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get numpy array of expression and neutral differences for each image (strong)\n",
    "import cv2\n",
    "import dlib\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Initialize variables for dLib\n",
    "predictor_path = \"/Users/kaili/Dropbox/HSSF1516/shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "# Initialize other variables\n",
    "NLA = []\n",
    "ELA = []\n",
    "tempLDA = []\n",
    "\n",
    "# Get landmarks for neutral images\n",
    "for root, dirs, files in os.walk(\"./Neutral\"):\n",
    "    for name in files:\n",
    "        filename = os.path.join(root, name)\n",
    "        # Read image if of correct type (8bit gray or RGB)\n",
    "        if '.png' in filename:\n",
    "            image = cv2.imread(filename, 1)\n",
    "            # Detect faces and initialize variables for next step\n",
    "            dets = detector(image, 1)\n",
    "            # Get list of x-coordinates and y-coordinates of facial landmarks for each face\n",
    "            for d in dets:\n",
    "                imageNA = []\n",
    "                shape = predictor(image, d)\n",
    "                for index in range(0, 68):\n",
    "                    point = shape.part(index)\n",
    "                    tuplepoint = (point.x, point.y)\n",
    "                    imageNA.append(tuplepoint)\n",
    "                NLA.append(imageNA)\n",
    "                \n",
    "# Get landmarks for expression images\n",
    "for root, dirs, files in os.walk(\"./Expression\"):\n",
    "    for name in files:\n",
    "        filename = os.path.join(root, name)\n",
    "\n",
    "        # Read image if of correct type (8bit gray or RGB)\n",
    "        if '.png' in filename:\n",
    "            image = cv2.imread(filename, 1)\n",
    "\n",
    "            # Detect faces and initialize variables for next step\n",
    "            dets = detector(image, 1)\n",
    "\n",
    "            # Get list of x-coordinates and y-coordinates of facial landmarks for each face\n",
    "            for d in dets:\n",
    "                imageEA = []\n",
    "                shape = predictor(image, d)\n",
    "                for index in range(0, 68):\n",
    "                    point = shape.part(index)\n",
    "                    tuplepoint = (point.x, point.y)\n",
    "                    imageEA.append(tuplepoint)\n",
    "                ELA.append(imageEA)\n",
    "\n",
    "# Get list of Euclidean differences for each landmark point for each image, convert list to numpy.arrray, add to big list\n",
    "for img in range(len(NLA)):\n",
    "    tempImgLDA = []\n",
    "    for point in range(68):\n",
    "        dif = math.sqrt((math.pow(ELA[img][point][0]-NLA[img][point][0], 2)) + (math.pow(ELA[img][point][1]-NLA[img][point][1], 2)))\n",
    "        tempImgLDA.append(dif)\n",
    "    imgLDA = np.asarray(tempImgLDA)\n",
    "    tempLDA.append(imgLDA)\n",
    "\n",
    "# Convert big list of all differences for all images to numpy.array\n",
    "LDA = np.asarray(tempLDA)\n",
    "\n",
    "# Subtract the average from the LDA values to see if there is any change\n",
    "for img in range(len(LDA)):\n",
    "    sum = 0\n",
    "    for valueIndex in range(len(LDA[img])):\n",
    "        sum+=LDA[img][valueIndex]\n",
    "    average = sum/68\n",
    "    for vI in range(len(LDA[img])):\n",
    "        LDA[img][vI]-=average\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-1-d64e5218f437>, line 143)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-d64e5218f437>\"\u001b[0;36m, line \u001b[0;32m143\u001b[0m\n\u001b[0;31m    print pCMatrix\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "# WORKING VERSION OF COMBINED DRAFTS-> STRONG EMOTION CLASSIFIERS\n",
    "# Create 327x3 matrix, for each image set contains neutral image name, expression image name, emotion label\n",
    "# Generate normalized Euclidean Differences array\n",
    "# Generate target values array\n",
    "# Feed to SVM, evaulate with Cross Validation\n",
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "import os\n",
    "import math\n",
    "from sklearn import svm\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Function that returns the distance between two given points\n",
    "def ptDist(pt1, pt2):\n",
    "    x1 = pt1[0]\n",
    "    x2 = pt2[0]\n",
    "    y1 = pt1[1]\n",
    "    y2 = pt2[1]\n",
    "    return math.sqrt((x1-x2)*(x1-x2) + (y1-y2)*(y1-y2))\n",
    "\n",
    "# Function that returns array of 68 landmarks for given image name\n",
    "def get68LMA(imgName):\n",
    "    predictor_path = \"/Users/kaili/Dropbox/HSSF1516/shape_predictor_68_face_landmarks.dat\"\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(predictor_path)\n",
    "    LMA = []\n",
    "    image = cv2.imread(imgName, 1)\n",
    "    \n",
    "    # Detect face(s)\n",
    "    dets = detector(image, 1)\n",
    "\n",
    "    # Get list of coordinates of 68 facial landmarks for each face\n",
    "    for d in dets:\n",
    "        shape = predictor(image, d)\n",
    "        for index in range(0, 68):\n",
    "            point = shape.part(index)\n",
    "            tuplepoint = (point.x, point.y)\n",
    "            LMA.append(tuplepoint)\n",
    "    return LMA\n",
    "\n",
    "# Function that eturns normalized array of Euclidean distances given two arrays of coordinates\n",
    "def getEucDist(nLA, eLA):\n",
    "    LDA = []\n",
    "    sum = 0\n",
    "    # Get array of distances\n",
    "    for pt in range(68):\n",
    "        dif = ptDist(eLA[pt], nLA[pt])     \n",
    "        LDA.append(dif)\n",
    "        sum += dif\n",
    "    avg = sum/68\n",
    "    # Normalize array\n",
    "    for i in range(68):\n",
    "        LDA[i] -= avg      \n",
    "    return LDA\n",
    "\n",
    "# Function that returns 13-point numpy vector of distances between selected physiological pts, given the 68-point vector\n",
    "def getPDA(iLA):\n",
    "    PDA = []\n",
    "    PDA.append(ptDist(iLA[20], iLA[21])) #distance 0: distance between brows\n",
    "    PDA.append(ptDist(iLA[20], iLA[26])) #distance 1: inner brow to nose- left\n",
    "    PDA.append(ptDist(iLA[21], iLA[26])) #distance 2: inner brow to nose- right\n",
    "    PDA.append(ptDist(iLA[20], iLA[38])) #distance 3: inner brow to inner eye corner- left\n",
    "    PDA.append(ptDist(iLA[21], iLA[41])) #distance 4: inner brow to inner eye corner- right\n",
    "    PDA.append(ptDist(iLA[35], iLA[47])) #distance 5: outer eye corner to outer mouth corner- left\n",
    "    PDA.append(ptDist(iLA[44], iLA[53])) #distance 6: outer eye corner to outer mouth corner- right\n",
    "    PDA.append(ptDist(iLA[47], iLA[53])) #distance 7: distance between mouth corners\n",
    "    PDA.append(ptDist(iLA[61], iLA[65])) #distance 8: height of mouth\n",
    "    PDA.append(ptDist(iLA[35], iLA[49])) #distance 9: raising of upper lip\n",
    "    PDA.append(ptDist(iLA[44], iLA[51])) #distance 10: raising of upper lip\n",
    "    PDA.append(ptDist(iLA[18], iLA[36])) #distance 11: brow arch- left\n",
    "    PDA.append(ptDist(iLA[23], iLA[43])) #distance 12: brow arch- right\n",
    "    return np.asarray(PDA)\n",
    "\n",
    "\"\"\"MAIN PROGRAM BEGINS\"\"\"\n",
    "# Get paths to face images and emotion labels\n",
    "imagedir = []\n",
    "labeldir = []\n",
    "root, dirs, files = os.walk(\"./cohn-kanade-images\",).next()\n",
    "for d in dirs:\n",
    "    imagedir.append(os.path.join(root,d))\n",
    "    labeldir.append(os.path.join('./Emotion',d))\n",
    "\n",
    "# initialize variables\n",
    "dataset = []\n",
    "NLA = []\n",
    "ELA = []\n",
    "\n",
    "# look over all directories of individuals S001 through S999\n",
    "for d in dirs:\n",
    "    for dd in os.listdir(os.path.join('./cohn-kanade-images',d)):\n",
    "        # skip over .DS_Store files\n",
    "        if 'Store' not in dd:\n",
    "            curdir = os.path.join('./cohn-kanade-images',d,dd)\n",
    "            files = os.listdir(curdir)\n",
    "            baseimage = os.path.join(curdir,files[0])\n",
    "            faceimage = os.path.join(curdir,files[-1])\n",
    "\n",
    "            # get directories of multiple expressions of same person\n",
    "            labeldir = os.path.join('./Emotion',d,dd)\n",
    "            if os.path.isdir(labeldir):\n",
    "                labels = os.listdir(labeldir)\n",
    "                # read label file if it exists\n",
    "                if len(labels)>0:\n",
    "                    f=open(os.path.join(labeldir,labels[0]),\"r\")\n",
    "                    for line in f:\n",
    "                        targetlabel = float(line)\n",
    "                    f.close()\n",
    "                    \n",
    "                    # append label to dataset\n",
    "                    dataset.append([baseimage, faceimage, targetlabel])\n",
    "\n",
    "\"\"\"68-POINT LANDMARK DETECTION MODEL\"\"\"\n",
    "# Get array of Euclidean differences between neutral and expression 68-landmark arrays\n",
    "tempLDA = []\n",
    "for imgIndex in range(len(dataset)):\n",
    "    nImgName = dataset[imgIndex][0]\n",
    "    eImgName = dataset[imgIndex][1]\n",
    "    nLA = get68LMA(nImgName)\n",
    "    eLA = get68LMA(eImgName)\n",
    "    NLA.append(nLA)\n",
    "    ELA.append(eLA)\n",
    "    tempLDA.append(getEucDist(nLA, eLA))\n",
    "LDA = np.asmatrix(tempLDA)\n",
    "\n",
    "# Create target value array for expression images\n",
    "tempTargetValues = []\n",
    "for imgSet in range(len(dataset)):\n",
    "    tempTargetValues.append(dataset[imgSet][2])\n",
    "targetValues = np.asarray(tempTargetValues)\n",
    "\n",
    "# Feed LDA and targetValues into SVM, use cross validation, generate confusion matrix\n",
    "x_train, x_test, y_train, y_test = cross_validation.train_test_split(LDA, targetValues, test_size=0.4, random_state=2)\n",
    "normCLF = svm.SVC(kernel='linear').fit(x_train, y_train)\n",
    "predictions = normCLF.predict(x_test)\n",
    "cmatrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Format CMatrix to show percentages, rounded to 1 decimal point\n",
    "np.set_printoptions(precision=1)\n",
    "rowSums = np.sum(cmatrix, axis=1)\n",
    "pCMatrix = np.divide(cmatrix*100., rowSums, dtype=float)\n",
    "print pCMatrix\n",
    "\n",
    "\n",
    "\"\"\"PHYSIOLOGICALLY BASED LANDMARK DETECTION MODEL\"\"\"\n",
    "# Get array of corresponding differences between 13 distances of base images and expression images\n",
    "tempPDA = []\n",
    "for i in range(len(NLA)):\n",
    "    tempPDA.append(getPDA(NLA[i])-getPDA(ELA[i]))\n",
    "PDA = np.asmatrix(tempPDA)\n",
    "np.savetxt('PDAfile', PDA) #Save PDA as human-readable format file\n",
    "\n",
    "# Feed PDA and targetValues into SVM, use cross validation, generate confusion matrix\n",
    "x_train2, x_test2, y_train2, y_test2 = cross_validation.train_test_split(PDA, targetValues, test_size=0.4, random_state=3)\n",
    "physCLF = svm.SVC(kernel='linear').fit(x_train2, y_train2)\n",
    "predictions2 = physCLF.predict(x_test2)\n",
    "cMatrix2 = confusion_matrix(y_test2, predictions2)\n",
    "\n",
    "# Format CMatrix2 to show percentages, already rounded to 1 decimal point\n",
    "rowSums2 = np.sum(cMatrix2, axis=1)\n",
    "pCMatrix2 = np.divide(cMatrix2*100., rowSums2, dtype=float)\n",
    "print pCMatrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
