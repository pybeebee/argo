{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train SVM with polynomial kernel\n",
    "# Create 327x3 matrix, for each image set contains neutral image name, expression image name, emotion label\n",
    "# Generate normalized Euclidean Differences array\n",
    "# Generate target values array\n",
    "# Feed to SVM, evaulate with Cross Validation\n",
    "\n",
    "\n",
    "\n",
    "##### SET UP METHODS #####\n",
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "import os\n",
    "import math\n",
    "from sklearn import svm\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Function that returns the distance between two given points\n",
    "def ptDist(pt1, pt2):\n",
    "    x1 = pt1[0]\n",
    "    x2 = pt2[0]\n",
    "    y1 = pt1[1]\n",
    "    y2 = pt2[1]\n",
    "    return math.sqrt((x1-x2)*(x1-x2) + (y1-y2)*(y1-y2))\n",
    "\n",
    "# Function that returns array of 68 landmarks for given image name\n",
    "def get68LMA(imgName):\n",
    "    predictor_path = \"/Users/kaili/Dropbox/HSSF1516/shape_predictor_68_face_landmarks.dat\"\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(predictor_path)\n",
    "    LMA = []\n",
    "    image = cv2.imread(imgName, 1)\n",
    "    \n",
    "    # Detect face(s)\n",
    "    dets = detector(image, 1)\n",
    "\n",
    "    # Get list of coordinates of 68 facial landmarks for each face\n",
    "    for d in dets:\n",
    "        shape = predictor(image, d)\n",
    "        for index in range(0, 68):\n",
    "            point = shape.part(index)\n",
    "            tuplepoint = (point.x, point.y)\n",
    "            LMA.append(tuplepoint)\n",
    "    return LMA\n",
    "\n",
    "# Function that eturns normalized array of Euclidean distances given two arrays of coordinates\n",
    "def getEucDist(nLA, eLA):\n",
    "    LDA = []\n",
    "    sum = 0\n",
    "    # Get array of distances\n",
    "    for pt in range(68):\n",
    "        dif = ptDist(eLA[pt], nLA[pt])     \n",
    "        LDA.append(dif)\n",
    "        sum += dif\n",
    "    avg = sum/68\n",
    "    # Normalize array\n",
    "    for i in range(68):\n",
    "        LDA[i] -= avg      \n",
    "    return LDA\n",
    "\n",
    "# Function that returns 13-point numpy vector of distances between selected physiological pts, given the 68-point vector\n",
    "def getPDA(iLA):\n",
    "    PDA = []\n",
    "    PDA.append(ptDist(iLA[20], iLA[21])) #distance 0: distance between brows\n",
    "    PDA.append(ptDist(iLA[20], iLA[26])) #distance 1: inner brow to nose- left\n",
    "    PDA.append(ptDist(iLA[21], iLA[26])) #distance 2: inner brow to nose- right\n",
    "    PDA.append(ptDist(iLA[20], iLA[38])) #distance 3: inner brow to inner eye corner- left\n",
    "    PDA.append(ptDist(iLA[21], iLA[41])) #distance 4: inner brow to inner eye corner- right\n",
    "    PDA.append(ptDist(iLA[35], iLA[47])) #distance 5: outer eye corner to outer mouth corner- left\n",
    "    PDA.append(ptDist(iLA[44], iLA[53])) #distance 6: outer eye corner to outer mouth corner- right\n",
    "    PDA.append(ptDist(iLA[47], iLA[53])) #distance 7: distance between mouth corners\n",
    "    PDA.append(ptDist(iLA[61], iLA[65])) #distance 8: height of mouth\n",
    "    PDA.append(ptDist(iLA[35], iLA[49])) #distance 9: raising of upper lip\n",
    "    PDA.append(ptDist(iLA[44], iLA[51])) #distance 10: raising of upper lip\n",
    "    PDA.append(ptDist(iLA[18], iLA[36])) #distance 11: brow arch- left\n",
    "    PDA.append(ptDist(iLA[23], iLA[43])) #distance 12: brow arch- right\n",
    "    return np.asarray(PDA)\n",
    "\n",
    "##### MAIN PROGRAM STARTS #####\n",
    "# Get paths to face images and emotion labels\n",
    "imagedir = []\n",
    "labeldir = []\n",
    "root, dirs, files = os.walk(\"./cohn-kanade-images2\",).__next__()\n",
    "for d in dirs:\n",
    "    imagedir.append(os.path.join(root,d))\n",
    "    labeldir.append(os.path.join('./Emotion',d))\n",
    "\n",
    "# initialize variables\n",
    "dataset = []\n",
    "NLA = []\n",
    "ELA = []\n",
    "\n",
    "# look over all directories of individuals S001 through S999\n",
    "for d in dirs:\n",
    "    for dd in os.listdir(os.path.join('./cohn-kanade-images2',d)):\n",
    "        # skip over .DS_Store files\n",
    "        if 'Store' not in dd:\n",
    "            curdir = os.path.join('./cohn-kanade-images2',d,dd)\n",
    "            files = os.listdir(curdir)\n",
    "            baseimage = os.path.join(curdir,files[0])\n",
    "            faceimage = os.path.join(curdir,files[-1])\n",
    "\n",
    "            # get directories of multiple expressions of same person\n",
    "            labeldir = os.path.join('./Emotion',d,dd)\n",
    "            if os.path.isdir(labeldir):\n",
    "                labels = os.listdir(labeldir)\n",
    "                # read label file if it exists\n",
    "                if len(labels)>0:\n",
    "                    f=open(os.path.join(labeldir,labels[0]),\"r\")\n",
    "                    for line in f:\n",
    "                        targetlabel = float(line)\n",
    "                    f.close()\n",
    "                    \n",
    "                    # append label to dataset\n",
    "                    if int(targetlabel)!=2:\n",
    "                        dataset.append([baseimage, faceimage, targetlabel])\n",
    "\n",
    "# Get array of Euclidean differences between neutral and expression 68-landmark arrays\n",
    "tempLDA = []\n",
    "for imgIndex in range(len(dataset)):\n",
    "    nImgName = dataset[imgIndex][0]\n",
    "    eImgName = dataset[imgIndex][1]\n",
    "    nLA = get68LMA(nImgName)\n",
    "    eLA = get68LMA(eImgName)\n",
    "    NLA.append(nLA)\n",
    "    ELA.append(eLA)\n",
    "    tempLDA.append(getEucDist(nLA, eLA))\n",
    "LDA = np.asmatrix(tempLDA)\n",
    "\n",
    "# Create target value array for expression images\n",
    "tempTargetValues = []\n",
    "for imgSet in range(len(dataset)):\n",
    "    tempTargetValues.append(dataset[imgSet][2])\n",
    "targetValues = np.asarray(tempTargetValues)\n",
    "\n",
    "##### TRAIN PHYSIOLOGICAL MODEL #####\n",
    "# Get array of corresponding differences between 13 distances of base images and expression images\n",
    "tempPDA = []\n",
    "for i in range(len(NLA)):\n",
    "    tempPDA.append(getPDA(NLA[i])-getPDA(ELA[i]))\n",
    "PDA = np.asmatrix(tempPDA)\n",
    "\n",
    "# Feed PDA and targetValues into SVM, use cross validation, generate confusion matrix\n",
    "x_train2, x_test2, y_train2, y_test2 = cross_validation.train_test_split(PDA, targetValues, test_size=0.4, random_state=3)\n",
    "physCLF = svm.SVC(kernel='poly').fit(x_train2, y_train2)\n",
    "predictions = physCLF.predict(x_test2)\n",
    "cMatrix = confusion_matrix(y_test2, predictions)\n",
    "print(cMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getPhysDA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4035bc07c146>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Get physiological feature vector for current frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetPhysDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetI68LMA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'getPhysDA' is not defined"
     ]
    }
   ],
   "source": [
    "# Capture video\n",
    "# Classify emotion\n",
    "# Output the emotion\n",
    "\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "cap = cv2.VideoCapture(0) # capture video from robot camera\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    "loaded = joblib.load('theModel.pkl')\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "images=[]\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    dets = detector(frame, 1)\n",
    "    \n",
    "    for rect in dets:\n",
    "        cv2.rectangle(frame, (rect.left(), rect.top()), (rect.right(), rect.bottom()), (0, 255, 0), 2)\n",
    "    cv2.imshow('frame',frame)\n",
    "\n",
    "    # Get physiological feature vector for current frame\n",
    "    images.append(getPhysDA(getI68LMA(frame)))\n",
    "    \n",
    "    if len(images)>2:\n",
    "        images.pop(0)\n",
    "    # Classify expression in image\n",
    "    if len(images)>1:\n",
    "        index=loaded.predict(np.asarray(images[0]-images[1])) # Get array of probabilities\n",
    "        print(index)\n",
    "        \n",
    "        # Print the emotion corresponding to the position\n",
    "        if index==1:\n",
    "            print(\"Anger\")\n",
    "        elif index==3:\n",
    "            print(\"Disgust\")\n",
    "        elif index==4:\n",
    "            print(\"Fear\")\n",
    "        elif index==5:\n",
    "            print(\"Happiness\")\n",
    "        elif index==6:\n",
    "            print(\"Sadness\")\n",
    "        elif index==7:\n",
    "            print(\"Surprise\")\n",
    "            \n",
    "    # Break out of while loop if 'q' key pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break      \n",
    "        \n",
    "# Release video capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaili/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surprise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaili/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surprise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaili/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happiness\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaili/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surprise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaili/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happiness\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaili/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surprise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaili/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surprise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaili/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaili/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surprise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaili/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaili/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surprise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaili/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surprise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaili/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surprise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaili/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surprise\n"
     ]
    }
   ],
   "source": [
    "# Capture video\n",
    "# Classify emotion\n",
    "# Output the emotion\n",
    "\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Function that returns the distance between two given points\n",
    "def ptDist(pt1, pt2):\n",
    "    x1 = pt1[0]\n",
    "    x2 = pt2[0]\n",
    "    y1 = pt1[1]\n",
    "    y2 = pt2[1]\n",
    "    return math.sqrt((x1-x2)*(x1-x2) + (y1-y2)*(y1-y2))\n",
    "\n",
    "# Function that returns array of 68 landmarks for given image name\n",
    "def get68LMA(imgName):\n",
    "    predictor_path = \"/Users/kaili/Dropbox/HSSF1516/shape_predictor_68_face_landmarks.dat\"\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(predictor_path)\n",
    "    LMA = []\n",
    "    image = cv2.imread(imgName, 1)\n",
    "    \n",
    "    # Detect face(s)\n",
    "    dets = detector(image, 1)\n",
    "\n",
    "    # Get list of coordinates of 68 facial landmarks for each face\n",
    "    shape = predictor(image, dets[0])\n",
    "    for index in range(0, 68):\n",
    "        point = shape.part(index)\n",
    "        tuplepoint = (point.x, point.y)\n",
    "        LMA.append(tuplepoint)\n",
    "    return LMA\n",
    "\n",
    "# Function that eturns normalized array of Euclidean distances given two arrays of coordinates\n",
    "def getEucDist(nLA, eLA):\n",
    "    LDA = []\n",
    "    sum = 0\n",
    "    # Get array of distances\n",
    "    for pt in range(68):\n",
    "        dif = ptDist(eLA[pt], nLA[pt])     \n",
    "        LDA.append(dif)\n",
    "        sum += dif\n",
    "    avg = sum/68\n",
    "    # Normalize array\n",
    "    for i in range(68):\n",
    "        LDA[i] -= avg      \n",
    "    return LDA\n",
    "\n",
    "# Method to get 68 landmarks for IMAGE passed to the function\n",
    "def getI68LMA(img):\n",
    "    predictor_path = \"/Users/kaili/Dropbox/HSSF1516/shape_predictor_68_face_landmarks.dat\"\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(predictor_path)\n",
    "    LMA = []\n",
    "    \n",
    "    # Detect face(s)\n",
    "    dets = detector(img, 1)\n",
    "\n",
    "    # Get list of coordinates of 68 facial landmarks for each face\n",
    "    if len(dets)>0:\n",
    "        shape = predictor(img, dets[0])\n",
    "        for index in range(0, 68):\n",
    "            point = shape.part(index)\n",
    "            tuplepoint = (point.x, point.y)\n",
    "            LMA.append(tuplepoint)\n",
    "        return LMA\n",
    "\n",
    "# Function that returns 13-point numpy vector of distances between selected physiological pts, given the 68-point vector\n",
    "def getPhysDA(iLA):\n",
    "    PDA = []\n",
    "    PDA.append(ptDist(iLA[20], iLA[21])) #distance 0: distance between brows\n",
    "    PDA.append(ptDist(iLA[20], iLA[26])) #distance 1: inner brow to nose- left\n",
    "    PDA.append(ptDist(iLA[21], iLA[26])) #distance 2: inner brow to nose- right\n",
    "    PDA.append(ptDist(iLA[20], iLA[38])) #distance 3: inner brow to inner eye corner- left\n",
    "    PDA.append(ptDist(iLA[21], iLA[41])) #distance 4: inner brow to inner eye corner- right\n",
    "    PDA.append(ptDist(iLA[35], iLA[47])) #distance 5: outer eye corner to outer mouth corner- left\n",
    "    PDA.append(ptDist(iLA[44], iLA[53])) #distance 6: outer eye corner to outer mouth corner- right\n",
    "    PDA.append(ptDist(iLA[47], iLA[53])) #distance 7: distance between mouth corners\n",
    "    PDA.append(ptDist(iLA[61], iLA[65])) #distance 8: height of mouth\n",
    "    PDA.append(ptDist(iLA[35], iLA[49])) #distance 9: raising of upper lip\n",
    "    PDA.append(ptDist(iLA[44], iLA[51])) #distance 10: raising of upper lip\n",
    "    PDA.append(ptDist(iLA[18], iLA[36])) #distance 11: brow arch- left\n",
    "    PDA.append(ptDist(iLA[23], iLA[43])) #distance 12: brow arch- right\n",
    "    return np.asarray(PDA)\n",
    "\n",
    "    \n",
    "cap = cv2.VideoCapture(0) # capture video from robot camera\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    "loaded = joblib.load('poly7.pkl')\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "images=[]\n",
    "\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    dets = detector(frame, 1)\n",
    "    \n",
    "    for rect in dets:\n",
    "        cv2.rectangle(frame, (rect.left(), rect.top()), (rect.right(), rect.bottom()), (0, 255, 0), 2)\n",
    "    cv2.imshow('frame',frame)\n",
    "\n",
    "    # Get physiological feature vector for current frame\n",
    "    images.append(getPhysDA(getI68LMA(frame)))\n",
    "    \n",
    "    if len(images)>2:\n",
    "        images.pop(0)\n",
    "    # Classify expression in image\n",
    "    if len(images)>1:\n",
    "        emo_probs = loaded.predict_proba(np.asarray(images[0]-images[1])) # Get array of probabilities\n",
    "        index = np.argmax(emo_probs)# Get position of highest probability\n",
    "#         if magnitude > 0.8:\n",
    "#             print(\"Strong\")\n",
    "#         elif magnitude > 0.4:\n",
    "#             print(\"Moderate\")\n",
    "        \n",
    "        # Print the emotion corresponding to the position\n",
    "        if index==0 or index==6:\n",
    "            print(\"Anger\")\n",
    "            #os.system(\"ssh pi@192.168.1.108 python emotions/anger.py\")\n",
    "        elif index==1 or index==7:\n",
    "            print(\"Disgust\")\n",
    "        elif index==2 or index==8:\n",
    "            print(\"Fear\")\n",
    "        elif index==3 or index==9:\n",
    "            print(\"Happiness\")\n",
    "            #os.system(\"ssh pi@192.168.1.108 python emotions/happiness.py\")\n",
    "        elif index==4 or index==10:\n",
    "            print(\"Sadness\")\n",
    "            #os.system(\"ssh pi@192.168.1.108 python emotions/sadness.py\")\n",
    "        elif index==5 or index==11:\n",
    "            print(\"Surprise\")\n",
    "            #os.system(\"ssh pi@192.168.1.108 python emotions/surprise.py\")\n",
    "            \n",
    "    # Break out of while loop if 'q' key pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break      \n",
    "        \n",
    "# Release video capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
