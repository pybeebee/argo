{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###### Motor Test 1\n",
    "\"\"\"\n",
    "Asks the user to select an output Port.\n",
    "Then the connected motor will turn 360 degree\n",
    "forwards and then backwards with maximum speed.\n",
    "\"\"\"\n",
    "\n",
    "import nxt.locator\n",
    "from nxt.motor import *\n",
    "\n",
    "def user_select_ouput_port():\n",
    "    \"\"\"\n",
    "    returns PORT_A, PORT_B or PORT_C\n",
    "    \"\"\"\n",
    "    port = 'B'\n",
    "    while port is None:\n",
    "        port = input(\"Please select a port where a motor is connected (A, B or C): \")\n",
    "        if port.upper() == 'A':\n",
    "            return PORT_A\n",
    "        elif port.upper() == 'B':\n",
    "            return PORT_B\n",
    "        elif port.upper() == 'C':\n",
    "            return PORT_C\n",
    "        port = None\n",
    "\n",
    "def select_and_spin(b):\n",
    "    port = PORT_A\n",
    "    motor = Motor(b, port)\n",
    "    motor.turn(5, 15)\n",
    "    motor.turn(-5, 40)\n",
    "\n",
    "b = nxt.locator.find_one_brick()\n",
    "select_and_spin(b)\n",
    "b.sock.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### NXT Test\n",
    "import sys, traceback\n",
    "\n",
    "if '--help' in sys.argv:\n",
    "    print(\"\"\"Tests the nxt-python setup and brick firmware interaction\n",
    "\n",
    "Usage: nxt_test           # Finds one brick and shows information about it\n",
    "       nxt_test --verbose # Shows more debug information when trying to find the brick\n",
    "       nxt_test --help    # Shows this help\n",
    "\"\"\")\n",
    "    exit(0)\n",
    "\n",
    "import nxt.locator\n",
    "import nxt.brick\n",
    "\n",
    "debug = False\n",
    "if '--verbose' in sys.argv:\n",
    "    debug = True\n",
    "\n",
    "b = None\n",
    "try:\n",
    "    b = nxt.locator.find_one_brick(debug=debug)\n",
    "    name, host, signal_strength, user_flash = b.get_device_info()\n",
    "    print('NXT brick name: %s' % name)\n",
    "    print('Host address: %s' % host)\n",
    "    print('Bluetooth signal strength: %s' % signal_strength)\n",
    "    print('Free user flash: %s' % user_flash)\n",
    "    prot_version, fw_version = b.get_firmware_version()\n",
    "    print('Protocol version %s.%s' % prot_version)\n",
    "    print('Firmware version %s.%s' % fw_version)\n",
    "    millivolts = b.get_battery_level()\n",
    "    print('Battery level %s mV' % millivolts)\n",
    "    b.sock.close()\n",
    "except:\n",
    "    print(\"Error while running test:\")\n",
    "    traceback.print_tb(sys.exc_info()[2])\n",
    "    print(str(sys.exc_info()[1]))\n",
    "    if b in locals():\n",
    "        b.sock.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Capture video from robot camera\n",
    "# Show video in color\n",
    "# Display box around face\n",
    "# Does NOT display facial landmarks for each face\n",
    "# SLOW Face Tracking\n",
    "\n",
    "import cv2\n",
    "import dlib\n",
    "import nxt.locator\n",
    "from nxt.motor import *\n",
    "\n",
    "cap = cv2.VideoCapture(1) # capture video from robot camera\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    "b = nxt.locator.find_one_brick() # connect to NXT brick\n",
    "\n",
    "# # Initialize variables for dLib\n",
    "# predictor_path = \"/Users/kaili/Dropbox/HSSF1516/shape_predictor_68_face_landmarks.dat\"\n",
    "# detector = dlib.get_frontal_face_detector()\n",
    "# predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Detect faces and initialize variables for next step\n",
    "    dets = detector(frame, 1)\n",
    "\n",
    "    # Draw a rectangle around the faces\n",
    "    for rect in dets:\n",
    "        cv2.rectangle(frame, (rect.left(), rect.top()), (rect.right(), rect.bottom()), (0, 255, 0), 2)\n",
    "        cv2.rectangle(frame, (0,0), (1,1), (0, 255, 0), 2)\n",
    "        facecenter=rect.center()\n",
    "        if facecenter.y>280:\n",
    "            Motor(b, PORT_B).turn(10, 10)\n",
    "        elif facecenter.y<200:\n",
    "            Motor(b, PORT_B).turn(-10, 10)\n",
    "        if facecenter.x>360:\n",
    "            Motor(b, PORT_A).turn(10, 10)\n",
    "        elif facecenter.x<280:\n",
    "            Motor(b, PORT_A).turn(-10, 10)\n",
    "        break\n",
    "\n",
    "    # Display frame, press 'q' to exit video window\n",
    "#     cv2.imshow('frame',frame)\n",
    "#      if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info[0] is ARGO\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\n",
      "Info[0] is ARGO\n",
      "Name parsed is 'ARGO'\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "/Users/jenkins/miniconda/1/x64/conda-bld/work/opencv-3.1.0/modules/highgui/src/window.cpp:281: error: (-215) size.width>0 && size.height>0 in function imshow\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cc5b16ab7e42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m#Display frame, press 'q' to exit video window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'frame'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xFF\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /Users/jenkins/miniconda/1/x64/conda-bld/work/opencv-3.1.0/modules/highgui/src/window.cpp:281: error: (-215) size.width>0 && size.height>0 in function imshow\n"
     ]
    }
   ],
   "source": [
    "# Capture video from robot camera\n",
    "# Show video in color\n",
    "# Display box around face using OPENCV HAAR CASCADE (NO DLIB)\n",
    "# Does NOT display facial landmarks for each face\n",
    "# SUPER FAST VERSION OF FACE TRACKING\n",
    "\n",
    "import cv2\n",
    "import dlib\n",
    "import nxt.locator\n",
    "from nxt.motor import *\n",
    "\n",
    "cap = cv2.VideoCapture(1) # capture video from robot camera\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    "b = nxt.locator.find_one_brick() # connect to NXT brick\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(\"/Users/kaili/Dropbox/OpenCV/haarcascades/haarcascade_frontalface_default.xml\")\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(frame, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        centerx = x+w/2\n",
    "        centery = y+h/2\n",
    "        # Draw a rectangle around the faces\n",
    "        if centery>280:\n",
    "            Motor(b, PORT_B).turn( 10, 10)\n",
    "        elif centery<200:\n",
    "            Motor(b, PORT_B).turn(-10, 10)\n",
    "        if centerx>360:\n",
    "            Motor(b, PORT_A).turn(10, 10)\n",
    "        elif centerx<280:\n",
    "            Motor(b, PORT_A).turn(-10, 10)\n",
    "        break\n",
    "\n",
    "    #Display frame, press 'q' to exit video window\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
